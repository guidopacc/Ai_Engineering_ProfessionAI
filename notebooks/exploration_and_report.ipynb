{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sentiment Reputation Monitoring - Esplorazione e Report\n",
        "\n",
        "Questo notebook documenta l'approccio, i risultati su campioni e idee di miglioramento per il sistema di monitoraggio della reputazione online.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "# Configurazione\n",
        "API_BASE_URL = \"http://localhost:8000\"\n",
        "SAMPLES_FILE = Path(\"../src/data/samples.jsonl\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Caricamento Campioni\n",
        "\n",
        "Carichiamo i campioni etichettati dal file `samples.jsonl`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Carica samples\n",
        "samples = []\n",
        "with open(SAMPLES_FILE, 'r') as f:\n",
        "    for line in f:\n",
        "        if line.strip():\n",
        "            samples.append(json.loads(line))\n",
        "\n",
        "df_samples = pd.DataFrame(samples)\n",
        "print(f\"Caricati {len(df_samples)} campioni\")\n",
        "print(f\"\\nDistribuzione label originale:\")\n",
        "print(df_samples['label'].value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Test API Locale\n",
        "\n",
        "Verifichiamo che l'API sia disponibile e testiamo le predizioni sui campioni.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Health check\n",
        "try:\n",
        "    response = requests.get(f\"{API_BASE_URL}/health\")\n",
        "    print(\"Health check:\", response.json())\n",
        "except Exception as e:\n",
        "    print(f\"API non disponibile. Avvia l'API con: uvicorn src.app.main:app --reload\")\n",
        "    print(f\"Errore: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test predizioni sui campioni\n",
        "predictions = []\n",
        "for idx, sample in enumerate(df_samples.itertuples()):\n",
        "    try:\n",
        "        response = requests.post(\n",
        "            f\"{API_BASE_URL}/predict\",\n",
        "            json={\"text\": sample.text},\n",
        "            timeout=10\n",
        "        )\n",
        "        if response.status_code == 200:\n",
        "            pred = response.json()\n",
        "            predictions.append({\n",
        "                \"text\": sample.text[:50],\n",
        "                \"expected_label\": sample.label,\n",
        "                \"predicted_label\": pred[\"label\"],\n",
        "                \"score\": pred[\"score\"],\n",
        "                \"match\": sample.label == pred[\"label\"]\n",
        "            })\n",
        "        else:\n",
        "            print(f\"Errore per sample {idx}: {response.status_code}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Errore per sample {idx}: {e}\")\n",
        "\n",
        "df_predictions = pd.DataFrame(predictions)\n",
        "if len(df_predictions) > 0:\n",
        "    print(f\"\\nRisultati predizioni:\")\n",
        "    print(df_predictions[[\"expected_label\", \"predicted_label\", \"match\"]])\n",
        "    accuracy = df_predictions[\"match\"].mean()\n",
        "    print(f\"\\nAccuracy: {accuracy:.2%}\")\n",
        "else:\n",
        "    print(\"Nessuna predizione disponibile. Avvia l'API prima.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Distribuzione Sentiment\n",
        "\n",
        "Analizziamo la distribuzione delle predizioni di sentiment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if len(df_predictions) > 0:\n",
        "    pred_dist = df_predictions[\"predicted_label\"].value_counts()\n",
        "    print(\"Distribuzione predizioni:\")\n",
        "    print(pred_dist)\n",
        "    \n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "    \n",
        "    expected_dist = df_samples[\"label\"].value_counts()\n",
        "    pred_dist_plot = df_predictions[\"predicted_label\"].value_counts()\n",
        "    \n",
        "    axes[0].bar(expected_dist.index, expected_dist.values, alpha=0.7, label=\"Attesa\")\n",
        "    axes[0].set_title(\"Distribuzione Label Attesa\")\n",
        "    axes[0].set_ylabel(\"Frequenza\")\n",
        "    \n",
        "    axes[1].bar(pred_dist_plot.index, pred_dist_plot.values, alpha=0.7, color=\"orange\", label=\"Predetta\")\n",
        "    axes[1].set_title(\"Distribuzione Label Predetta\")\n",
        "    axes[1].set_ylabel(\"Frequenza\")\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Nessun dato disponibile per visualizzazione\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Calcolo Drift (KL Divergence)\n",
        "\n",
        "Calcoliamo la KL divergence tra distribuzione di riferimento (baseline) e distribuzione corrente per rilevare concept drift.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importa funzione di drift\n",
        "import sys\n",
        "sys.path.append('../src')\n",
        "from utils.drift import kl_divergence, compute_reference_distribution, windowed_label_distribution\n",
        "\n",
        "if len(df_predictions) > 0:\n",
        "    baseline_dist = compute_reference_distribution(df_samples[\"label\"].tolist())\n",
        "    print(\"Distribuzione baseline (riferimento):\")\n",
        "    print(baseline_dist)\n",
        "    \n",
        "    current_labels = df_predictions[\"predicted_label\"].tolist()\n",
        "    current_dist = compute_reference_distribution(current_labels)\n",
        "    print(\"\\nDistribuzione corrente (predizioni):\")\n",
        "    print(current_dist)\n",
        "    \n",
        "    kl_value = kl_divergence(baseline_dist, current_dist)\n",
        "    print(f\"\\nKL Divergence: {kl_value:.4f}\")\n",
        "    print(f\"Interpretazione: {'Drift rilevato' if kl_value > 0.1 else 'Distribuzione stabile'}\")\n",
        "else:\n",
        "    print(\"Nessun dato disponibile per calcolo drift\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Analisi Finestre Mobili\n",
        "\n",
        "Simuliamo il calcolo di drift su finestre mobili (windowed analysis).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if len(df_predictions) > 0:\n",
        "    labels_series = df_predictions[\"predicted_label\"].tolist()\n",
        "    window_size = 5\n",
        "    \n",
        "    window_distributions = windowed_label_distribution(labels_series, window_size)\n",
        "    \n",
        "    kl_values = []\n",
        "    for dist in window_distributions:\n",
        "        kl = kl_divergence(baseline_dist, dist)\n",
        "        kl_values.append(kl)\n",
        "    \n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.plot(kl_values, marker='o')\n",
        "    plt.axhline(y=0.1, color='r', linestyle='--', label='Soglia drift (0.1)')\n",
        "    plt.xlabel('Finestra Temporale')\n",
        "    plt.ylabel('KL Divergence')\n",
        "    plt.title('Drift Detection su Finestre Mobili')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"Media KL divergence: {np.mean(kl_values):.4f}\")\n",
        "    print(f\"Max KL divergence: {np.max(kl_values):.4f}\")\n",
        "else:\n",
        "    print(\"Nessun dato disponibile\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusioni e Sviluppi Futuri\n",
        "\n",
        "### Risultati\n",
        "- Modello utilizzato: `cardiffnlp/twitter-roberta-base-sentiment-latest`\n",
        "- Accurtezza su campioni di test: da valutare in base ai risultati sopra\n",
        "- Drift detection: implementato con KL divergence\n",
        "\n",
        "### Miglioramenti Possibili\n",
        "\n",
        "- Alerting automatico quando KL divergence supera soglia\n",
        "- Fine-tuning del modello su dominio specifico se necessario\n",
        "- Integrazione con API social per raccolta dati automatica\n",
        "- Rate limiting per proteggere l'API da sovraccarico\n",
        "- Caching delle predizioni per testi frequenti\n",
        "- Retraining periodico con nuovi dati per mantenere accuratezza\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
